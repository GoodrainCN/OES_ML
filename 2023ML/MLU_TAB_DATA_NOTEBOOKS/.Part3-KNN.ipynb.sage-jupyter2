{"backend_state":"init","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"type":"settings"}
{"cell_type":"code","id":"01b394","input":"print(df[numerical_features_all].isna().sum())","pos":24,"type":"cell"}
{"cell_type":"code","id":"0e65e3","input":"from sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\n\n### PIPELINE ###\n################\n\n# Pipeline desired data transformers, along with an estimator at the end\n# For each step specify: a name, the actual transformer/estimator with its parameters\nclassifier = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', MinMaxScaler()),\n    ('estimator', KNeighborsClassifier(n_neighbors = 3))\n])\n\n# Visualize the pipeline\n# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\nfrom sklearn import set_config\nset_config(display='diagram')\nclassifier","pos":34,"type":"cell"}
{"cell_type":"code","id":"11f30e","input":"print('Training set shape:', train_data.shape)\n\nprint('Class 1 samples in the training set:', sum(train_data[model_target] == 1))\nprint('Class 0 samples in the training set:', sum(train_data[model_target] == 0))","pos":32,"type":"cell"}
{"cell_type":"code","id":"1accb5","input":"import pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n  \ndf = pd.read_csv('data/review/review_dataset.csv')\n\nprint('The shape of the dataset is:', df.shape)","pos":3,"type":"cell"}
{"cell_type":"code","id":"1b2491","input":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n\n# Get test data to test the classifier\nX_test = test_data[numerical_features_all]\ny_test = test_data[model_target]\n\n# Use the fitted model to make predictions on the test dataset\n# Test data going through the Pipeline it's first imputed (with means from the train), scaled (with the min/max from the train data), and finally used to make predictions\ntest_predictions = classifier.predict(X_test)\n\nprint('Model performance on the test set:')\nprint(confusion_matrix(y_test, test_predictions))\nprint(classification_report(y_test, test_predictions))\nprint(\"Test accuracy:\", accuracy_score(y_test, test_predictions))","pos":40,"type":"cell"}
{"cell_type":"code","id":"30b841","input":"for c in numerical_features_all:\n    print(c)\n    print('min:', df[c].min(), 'max:', df[c].max())","pos":19,"type":"cell"}
{"cell_type":"code","id":"3c3f0e","input":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndf[model_target].value_counts().plot.bar()\nplt.show()","pos":14,"scrolled":true,"type":"cell"}
{"cell_type":"code","id":"583983","input":"model_features = df.columns.drop('Outcome Type')\nmodel_target = 'Outcome Type'\n\nprint('Model features: ', model_features)\nprint('Model target: ', model_target)","pos":10,"type":"cell"}
{"cell_type":"code","id":"64be15","input":"from sklearn.model_selection import train_test_split\n\ntrain_data, test_data = train_test_split(df, test_size=0.1, shuffle=True, random_state=23)","pos":27,"type":"cell"}
{"cell_type":"code","id":"711e39","input":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfor c in numerical_features_all:\n    print(c)\n    df[c].plot.hist(bins=5)\n    plt.show()","pos":17,"type":"cell"}
{"cell_type":"code","id":"9317e2","input":"import numpy as np\nnumerical_features_all = df[model_features].select_dtypes(include=np.number).columns\nprint('Numerical columns:',numerical_features_all)\n\nprint('')\n\ncategorical_features_all = df[model_features].select_dtypes(include='object').columns\nprint('Categorical columns:',categorical_features_all)\n","pos":12,"type":"cell"}
{"cell_type":"code","id":"941734","input":"for c in numerical_features_all: \n    print(c)\n    print(df[c].value_counts(bins=10, sort=False))\n    plt.show()","pos":21,"type":"cell"}
{"cell_type":"code","id":"a5fcdb","input":"# Let's see the data types and non-null values for each column\ndf.info()","pos":6,"type":"cell"}
{"cell_type":"code","id":"a7db2d","input":"# Print the first five rows\n# NaN means missing data\ndf.head()","pos":5,"type":"cell"}
{"cell_type":"code","id":"ac0a98","input":"print(df.columns)","pos":9,"type":"cell"}
{"cell_type":"code","id":"b25970","input":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n\n# Use the fitted model to make predictions on the train dataset\n# Train data going through the Pipeline it's first imputed (with means from the train), scaled (with the min/max from the train data), and finally used to make predictions\ntrain_predictions = classifier.predict(X_train)\n\nprint('Model performance on the train set:')\nprint(confusion_matrix(y_train, train_predictions))\nprint(classification_report(y_train, train_predictions))\nprint(\"Train accuracy:\", accuracy_score(y_train, train_predictions))","pos":38,"type":"cell"}
{"cell_type":"code","id":"c3cc70","input":"# Get train data to train the classifier\nX_train = train_data[numerical_features_all]\ny_train = train_data[model_target]\n\n# Fit the classifier to training data\n# Train data going through the Pipeline it's first imputed, then scaled, and finally used to fit the estimator\nclassifier.fit(X_train, y_train)\n","pos":36,"type":"cell"}
{"cell_type":"code","id":"e345f7","input":"print('Training set shape:', train_data.shape)\n\nprint('Class 0 samples in the training set:', sum(train_data[model_target] == 0))\nprint('Class 1 samples in the training set:', sum(train_data[model_target] == 1))\n\nprint('Class 0 samples in the test set:', sum(test_data[model_target] == 0))\nprint('Class 1 samples in the test set:', sum(test_data[model_target] == 1))","pos":29,"type":"cell"}
{"cell_type":"code","id":"e3df25","input":"# This prints basic statistics for numerical columns\ndf.describe()","pos":7,"type":"cell"}
{"cell_type":"code","id":"e58416","input":"from sklearn.utils import shuffle\n\nclass_0_no = train_data[train_data[model_target] == 0]\nclass_1_no = train_data[train_data[model_target] == 1]\n\nupsampled_class_0_no = class_0_no.sample(n=len(class_1_no), replace=True, random_state=42)\n\ntrain_data = pd.concat([class_1_no, upsampled_class_0_no])\ntrain_data = shuffle(train_data)","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"06b667","input":"From the target plots we can identify whether or not we are dealing with imbalanced datasets - this means one result type is dominating the other one(s). \n\nHandling class imbalance is highly recommended, as the model performance can be greatly impacted. In particular the model may not work well for the infrequent classes, as there are not enough samples to learn patterns from, and so it would be hard for the classifier to identify and match those patterns. \n\nWe might want to downsample the dominant class or upsample the rare the class, to help with learning its patterns. However, we should only fix the imbalance in training set, without changing the validation and test sets, as these should follow the original distribution. We will perform this task after train/test split. \n","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"14b936","input":"If for some histograms the values are heavily placed in the first bin, it is good to check for outliers, either checking the min-max values of those particular features and/or explore value ranges.","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"23a93f","input":"## 3. <a name=\"3\">Select features to build the model</a>\n(<a href=\"#0\">Go to top</a>)\n\nWe only consider the __numerical features__ to build the model for this first sample solution. \n\nLet's examine the numerical features.","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"24db93","input":"## 7. <a name=\"7\">Test the classifier</a>\n(<a href=\"#0\">Go to top</a>)\n\nLet's evaluate the performance of the trained classifier. We use __.predict()__ this time. \n\nLet's first see how the model works on the training dataset.","pos":37,"type":"cell"}
{"cell_type":"markdown","id":"3b7922","input":"__Important note:__ We want to fix the imbalance only in training set. We shouldn't change the validation and test sets, as these should follow the original distribution.","pos":30,"type":"cell"}
{"cell_type":"markdown","id":"49b50d","input":"#### Target balancing","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"4fc1d1","input":"With __value_counts()__ function, we can increase the number of histogram bins to 10 for more bins for a more refined view of the numerical features.","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"4fdbae","input":"If any outliers are identified as very likely wrong values, dropping them could improve the numerical values histograms, and later overall model performance. While a good rule of thumb is that anything not in the range of (Q1 - 1.5 IQR) and (Q3 + 1.5 IQR) is an outlier, other rules for removing 'outliers' should be considered as well. ","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"5144c4","input":"If any missing values, as a quick fix, we can apply mean imputation. This will replace the missing values with the mean value of the corresponding column.\n\n__Note__: The statistically correct way to perform mean/mode imputation before training an ML model is to compute the column-wise means on the training data only, and then use these values to impute missing data in both the train and test sets. So, you'll need to split your dataset first.\n\nAlso, more exploratory data analysis might reveal other important hidden atributes and/or relationships of the model features considered. ","pos":25,"type":"cell"}
{"cell_type":"markdown","id":"617194","input":"We can explore the features set further, figuring out first what features are numerical or categorical. Beware that some integer-valued features could actually be categorical features, and some categorical features could be text features. ","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"617dd8","input":"Let's check missing values for these numerical features.","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"67d6c0","input":"## 8. <a name=\"8\">Improvement ideas</a>\n(<a href=\"#0\">Go to top</a>)\n\n* Tune K parameter: You can use the [__train_test_split()__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function on the training set, create a validation set,  and search for optimum K value using the validation performance.\n","pos":41,"type":"cell"}
{"cell_type":"markdown","id":"77a7a4","input":"And now, let's evaluate the performance of the classifier on the test set.","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"824c7f","input":"## 1. <a name=\"1\">Read the dataset</a>\n(<a href=\"#0\">Go to top</a>)\n\nLet's read the dataset into a dataframe, using Pandas.","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"931f24","input":"## 6. <a name=\"6\">Train a classifier</a>\n(<a href=\"#0\">Go to top</a>)\n\nWe train our classifier with __.fit()__ on our training dataset. ","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"aae234","input":"# <a name=\"0\">Machine Learning Accelerator - Tabular Data - Lecture 1</a>\n\n\n## K Nearest Neighbors Model \n\nIn this notebook, we build a [__K Nearest Neighbors Classifier__](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to predict the __Outcome Type__ field of our review dataset.\n\n1. <a href=\"#1\">Read the dataset</a>\n2. <a href=\"#2\">Exploratory Data Analysis</a>\n3. <a href=\"#3\">Select features to build the model</a>\n4. <a href=\"#4\">Training and test datasets</a>\n5. <a href=\"#5\">Data processing with Pipeline</a>\n6. <a href=\"#6\">Train a classifier</a>\n7. <a href=\"#7\">Test the classifier</a>\n8. <a href=\"#8\">Improvement ideas</a>\n\n__Austin Animal Center Dataset__:\n\nIn this exercise, we are working with pet adoption data from __Austin Animal Center__. We have two datasets that cover intake and outcome of animals. Intake data is available from [here](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm) and outcome is from [here](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238). \n\nIn order to work with a single table, we joined the intake and outcome tables using the \"Animal ID\" column and created a single __review.csv__ file. We also didn't consider animals with multiple entries to the facility to keep our dataset simple. If you want to see the original datasets and the merged data with multiple entries, they are available under data/review folder: Austin_Animal_Center_Intakes.csv, Austin_Animal_Center_Outcomes.csv and Austin_Animal_Center_Intakes_Outcomes.csv.\n\n__Dataset schema:__ \n- __Pet ID__ - Unique ID of pet\n- __Outcome Type__ - State of pet at the time of recording the outcome (0 = not placed, 1 = placed). This is the field to predict.\n- __Sex upon Outcome__ - Sex of pet at outcome\n- __Name__ - Name of pet \n- __Found Location__ - Found location of pet before entered the center\n- __Intake Type__ - Circumstances bringing the pet to the center\n- __Intake Condition__ - Health condition of pet when entered the center\n- __Pet Type__ - Type of pet\n- __Sex upon Intake__ - Sex of pet when entered the center\n- __Breed__ - Breed of pet \n- __Color__ - Color of pet \n- __Age upon Intake Days__ - Age of pet when entered the center (days)\n- __Age upon Outcome Days__ - Age of pet at outcome (days)\n","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"b9f320","input":"## 4. <a name=\"4\">Training and test datasets</a>\n(<a href=\"#0\">Go to top</a>)\n\nWe split our dataset into training (90%) and test (10%) subsets using sklearn's [__train_test_split()__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"c7b487","input":"![MLU Logo](data/MLU_Logo.png)","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"d07865","input":"## 2. <a name=\"2\">Exploratory Data Analysis</a>\n(<a href=\"#0\">Go to top</a>)\n\nWe will look at number of rows, columns and some simple statistics of the dataset.","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"e967d5","input":"## 5. <a name=\"5\">Data processing with Pipeline</a>\n(<a href=\"#0\">Go to top</a>)\n\nIn a typical machine learning workflow you will need to apply data transformations, like imputation and scaling shown here, at least twice. First on the training dataset with __.fit()__ and __.transform()__, when preparing the data to training the model. And again, on any new data you want to predict on, with _-.transform()__. Scikit-learn [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) is a tool that simplifies this process by enforcing the implementation and order of data processing steps. \n\nWe build a pipeline to impute the missing values with the mean using sklearn's SimpleImputer, scale the numerical features to have similar orders of magnitude by bringing them into the 0-1 range with sklearn's MinMaxScaler, and finally train an estimator [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) on the imputed and scaled dataset. \n","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"ec874a","input":"Let's separate model features and model target. ","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"f5f170","input":"#### Target distribution\n\nLet's check our target distribution.","pos":13,"type":"cell"}
{"id":0,"time":1675385800521,"type":"user"}
{"last_load":1675385800758,"type":"file"}