{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer Example\n",
    "For our next example, we'll load a breast cancer dataset that classifies tumors as benign (0) or malignant(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(cancer.data,\n",
    "                 columns = cancer.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perform the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9578207381370826\n"
     ]
    }
   ],
   "source": [
    "y = cancer.target\n",
    "\n",
    "model = LogisticRegression(multi_class = \"auto\", solver = 'lbfgs', max_iter=10000)\n",
    "model.fit(X, y)\n",
    "print(model.score(X,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy was 96%. To see exactly which ones were mislabeled, we can view a confusion matrix. We can see that fifteen benign tumors were incorrectly mislabeled as malignant and nine malignant tumors were incorrectly mislabeled as a benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[197,  15],\n",
       "       [  9, 348]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "confusion_matrix(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cost Benefit Example: \n",
    "\n",
    "We can also optimize our models based on specific costs associated with our classification errors; here we will use specific dollar amounts as weights.\n",
    "\n",
    "For this example let's assume that a true breast cancer positive early detection would \n",
    "save the company 100000 dollars in later treatment and legal fees, a false negative would cost the insurance company 50,000 in later treatment, a false positive would cost 500 dollars in more screening, and a true negative would cost the company 100 in screening fees.  \n",
    "\n",
    "Then given the confusion matrix $[[198,  14], [  9, 348]]$ above, the expected value of offering the breast cancer screening would be:\n",
    "\n",
    "\\text{Expected_Value} = (100000)\\#TPs + (-50000)\\#FNs+(-500)\\#FPs+(-100)\\#TNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Accuracy, Recall, Precision, F Score\n",
    "Let's get into a bit more specifics about what types of errors we can make.\n",
    "\n",
    "![title](images/errors.png)\n",
    "\n",
    "**Accuracy** is the one we are most used to. It is defined as:\n",
    "\n",
    "$\\text{Accuracy} = \\frac{\\text{True Positive + True Negative}}{\\text{True Positive + True Negative + False Positive + False Negative}}$\n",
    "\n",
    "Or more simply, as:\n",
    "\n",
    "$\\text{Accuracy} = \\frac{\\text{Correct samples}}{\\text{All samples}}$\n",
    "\n",
    "In our iris example, 96% of our classifications were correct and 4% were incorrect.\n",
    "\n",
    "Many times, though, accuracy may not be the best measure. For example, suppose that 1% of a sample has breast cancer and 99% doesn't. Let's say your model simply spits out that no one has breast cancer. Then your model is 99% accurate. Sounds pretty good, right? We should probably aim to do better.\n",
    "\n",
    "Let's now define another measure of error, **recall** (also known as **sensitivity**).\n",
    "\n",
    "$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}$\n",
    "\n",
    "in other words:\n",
    "\n",
    "$\\text{Recall} = \\frac{\\text{True Positive Predictions}}{\\text{All Positive samples}}$\n",
    "\n",
    "Going back to the breast cancer example, recall answers the question \"Out of all the (few) positive cases, how many did I actually find?\" A model with high recall has a small number of false negatives.\n",
    "\n",
    "Another measure of error is called **precision**.\n",
    "\n",
    "$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives + False Positives}}$\n",
    "\n",
    "in other words:\n",
    "\n",
    "$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{All samples predicted to be positive}}$\n",
    "\n",
    "Going back to our breast cancer example, precision answers the question \"Out of all cases I predicted as positive, how many times was I right?\" A model with high precision has a small number of false positives.\n",
    "\n",
    "Suppose a computer program for recognizing dogs in photographs identifies 8 dogs in a picture containing 12 dogs and some cats. Of the 8 identified as dogs, 5 actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12. When a search engine returns 30 pages only 20 of which were relevant while failing to return 40 additional relevant pages, its precision is 20/30 = 2/3 while its recall is 20/60 = 1/3. So, in this case, precision is \"how useful the search results are\", and recall is \"how complete the results are\".\n",
    "\n",
    "\n",
    "A model with high recall and low precision will have most positive examples correctly recognized (low false negative rate) but there will be a lot of false positives (probably scaring a lot of women unncessarily if we're talking about the breast cancer example).\n",
    "\n",
    "A model with low recall and high precision will miss a lot of positive examples (high false negative rate) but those which we predict as positive are indeed positive (low false positive rate). This type of model would not scare women unnecessarily but would miss a lot of detections in women that did indeed have breast cancer.\n",
    "\n",
    "We do have a third measure, called the **F1 score**, that balances precision and recall; it is the harmonic mean of the two:\n",
    "\n",
    "$F_1 = 2* \\frac{\\text{precision}*\\text{recall}}{\\text{precision}+\\text{recall}}$\n",
    "\n",
    "\n",
    "The **support** is the number of samples of the true response that lie in that class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, there is a scikit-learn function that gives us all of these measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       212\n",
      "           1       0.96      0.97      0.97       357\n",
      "\n",
      "    accuracy                           0.96       569\n",
      "   macro avg       0.96      0.95      0.95       569\n",
      "weighted avg       0.96      0.96      0.96       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret this. \n",
    "- With a precision score of 96%, out of all cases predicted as benign, we were correct 96% of the time. With a recall score of 93%, out of all benign tumors, we found 93% of them.\n",
    "- With a precision score of 96%, out of all cases predicted as malignant, we were correct 96% of the time. With a recall score of 97%, out of all malignant tumors, we found 97% of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC-ROC Curves\n",
    "\n",
    "If we wanted to we could interpret recall as the True Positive Rate (TPR). Recall that recall is given by:\n",
    "\n",
    "$\\text{Recall/TPR} = \\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}$\n",
    "\n",
    "Going back to the breast cancer example, recall answers the question \"Out of all the (few) positive cases, how many did I actually find?\"\n",
    "\n",
    "Another measure of error will be specificity. **Specificity** is defined as:\n",
    "\n",
    "$\\text{Specificity} = \\frac{\\text{True Negatives}}{\\text{True Negatives + False Positives}}$\n",
    "\n",
    "Suppose in a product survey most people liked ice cream. Specificity answers the question \"Out of all the (few) negative cases that didn't like ice cream, how many did I actually find?\"\n",
    "\n",
    "The False Positive Rate (FPR) is given by:\n",
    "\n",
    "$\\text{FPR} = 1- \\text{Specificity} = \\frac{\\text{False Positives}}{\\text{True Negatives + False Positives}}$\n",
    "\n",
    "We can plot a model in ROC (Receiver Operating Characteristic) space by plotting the False Positive Rate against the True Positive Rate:\n",
    "\n",
    "<img src=\"images/roc2.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best possible prediction method would yield a point in the upper left corner or coordinate (0,1) of the ROC space, representing 100% sensitivity (no false negatives) and 100% specificity (no false positives). The (0,1) point is also called a perfect classification. A random guess would give a point along a diagonal line (the so-called line of no-discrimination) from the left bottom to the top right corners (regardless of the positive and negative base rates). An intuitive example of random guessing is a decision by flipping coins. As the size of the sample increases, a random classifier's ROC point tends towards the diagonal line. In the case of a balanced coin, it will tend to the point (0.5, 0.5). One can achieve any level of performance on this line by flipping a weighted coin to decide between two categories.\n",
    "\n",
    "The diagonal divides the ROC space. Points above the diagonal represent good classification results (better than random); points below the line represent bad results (worse than random). Note that the output of a consistently bad predictor could simply be inverted to obtain a good predictor.\n",
    "\n",
    "Let us look into four prediction results from 100 positive and 100 negative instances:\n",
    "\n",
    "<img src=\"images/tables.png\" width=\"600\">\n",
    "\n",
    "Plots of the four results above in the ROC space are given in the figure. The result of method A clearly shows the best predictive power among A, B, and C. The result of B lies on the random guess line (the diagonal line), and it can be seen in the table that the accuracy of B is 50%. However, when C is mirrored across the center point (0.5,0.5), the resulting method C′(top left, the ' is really hard to see) is even better than A. This mirrored method simply reverses the predictions of whatever method or test produced the C contingency table. Although the original C method has negative predictive power, simply reversing its decisions leads to a new predictive method C′ which has positive predictive power. When the C method predicts p or n, the C′ method would predict n or p, respectively. In this manner, the C′ test would perform the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model we have been using set a 50% threshold for determining classifications. In the graphic below, if the probability was above 50%, then the object was classified as an apple:\n",
    "\n",
    "<img src=\"images/apple.png\" width=\"500\">\n",
    "\n",
    "If you wanted to reduce the false positive rate, you could move the threshold up (so that an object got classified as an apple only if the probability was above 70%, for example.) If you wanted to reduce the false negative rate, you could move the threshold down (so that an object got classified as an apple if the probability was above 30%, for example.) Each threshold is a different model. If you move that threshold from 0 to 1 then at each threshold value, you will have a certain TPR and a certain FPR. Plotting each coordinate gives you a model's ROC curve:\n",
    "\n",
    "<img src=\"images/roc.png\" width=\"300\">\n",
    "\n",
    "AUC is defined as the area under the ROC curve. A perfect model has AUC of the 1 which means it has good measure of separability. \n",
    "\n",
    "<img src=\"images/roc3.png\" width=\"600\">\n",
    "\n",
    "In reality, though, most of our ROC curves will look more like this:\n",
    "\n",
    "<img src=\"images/roc4.png\" width=\"600\">\n",
    "\n",
    "We can compare models and choose the one with the highest AUC.\n",
    "\n",
    "(source: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to our breast cancer example, let's do a test/train split and calculate the AUC score:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9440559440559441\n",
      "ROC-AUC: 0.9880165289256198\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)\n",
    "\n",
    "model = LogisticRegression(multi_class = \"auto\", solver = 'lbfgs', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# accuracy for test & train:    \n",
    "y_proba_LR = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calculate AUC\n",
    "print('accuracy:', model.score(X_test,y_test))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the ROC plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(ytrue, yproba, model, title='some ROC curve'):\n",
    "    auc = roc_auc_score(ytrue, yproba)\n",
    "    fpr, tpr, thr = roc_curve(ytrue, yproba)\n",
    "    plt.plot([0, 1], [0, 1], color='k', linestyle='--', linewidth=.4)\n",
    "    plt.plot(fpr, tpr, label='{} auc={:.2f}%'.format(model, auc*100))\n",
    "    plt.axis('equal')\n",
    "    plt.xlim([-.02, 1.02])\n",
    "    plt.ylim([-.02, 1.02])\n",
    "    plt.ylabel('tpr')\n",
    "    plt.xlabel('fpr')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    \n",
    "plot_roc(y_test, y_proba_LR, \"Log Reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "A classifying technique that sometimes provides greater accuracy than logistic regression is the gradient boosting classifer. Let's try it out on the breast cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9370629370629371\n",
      "ROC-AUC: 0.9762396694214877\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# accuracy for test & train:    \n",
    "y_proba_GB = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#calculate AUC\n",
    "print('accuracy:', model.score(X_test,y_test))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_proba_GB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the Naive Bayes, logistic regression, and gradient boosting ROC curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "   \n",
    "y_proba_NB = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_proba_NB, \"Naive Bayes\")\n",
    "plot_roc(y_test, y_proba_GB, \"Gradient Boosting\")\n",
    "plot_roc(y_test, y_proba_LR, \"Log Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework - #1 Digits\n",
    "\n",
    "Read in the digit example from yesterday. Do a 70/30 train/test split and then print a classification report for your logistic regression algorithm. Then, in words, write what the precision and recall scores that you get mean for the digits 1 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW #2 - Hyperthyroid\n",
    "\n",
    "There is an excellent hyperthyroid example listed [here](http://gim.unmc.edu/dxtests/ROC1.htm) and [here](http://gim.unmc.edu/dxtests/roc2.htm).  List the accuracy, recall/sensitivity/true positive rate, precision, support, specificity, and false negative rate for each of the three threshold values. Also make sure you understand how the ROC curve is obtained. There will be a quiz on exactly this question with different numbers next week.\n",
    "\n",
    "<img src=\"images/hyper2.png\" width=\"300\">\n",
    "<img src=\"images/hyper1.png\" width=\"300\">\n",
    "<img src=\"images/hyper3.png\" width=\"300\">\n",
    "<img src=\"images/hyper5.png\" width=\"300\">\n",
    "<img src=\"images/hyper4.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert here"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd480433b0168f0b96e5ec847e914a92fdec64b0a6a89ef8313bf2e63f32d212"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pyc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
